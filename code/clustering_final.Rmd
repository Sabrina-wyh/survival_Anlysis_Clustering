---
title: "survival analysis"
author: "Yihan Wang"
date: "2025-01-04"
output: word_document
---

```{r}
rm(list = ls())
```

```{r}
library(survival)
library(broom)
library(ggplot2)
library(dplyr)
library(caret)
library(pROC)
library(longitudinalData)
library(doParallel)
library(foreach)
library(dtw)
library(cluster)  
library(factoextra)
library(parallel)
library(timeROC)
library(missRanger)
library(gridExtra)
set.seed(42)
```

```{r}
missranger_impute <- function(df, columns_ignores) {
  if (!is.data.frame(df)) {
    stop("The input must be a dataframe.")
  }
  if (!all(columns_ignores %in% colnames(df))) {
    stop("Some ID columns specified are not present in the dataframe.")
  }


  ignore_cols <- df[, columns_ignores, drop = FALSE]
  data_to_impute <- df[, !colnames(df) %in% columns_ignores, drop = FALSE]
  set.seed(42)
  imputed_data <- missRanger(data_to_impute, pmm.k = 10)
  result <- cbind(ignore_cols, imputed_data)
  return(result)
}
```


```{r}
external_validation_time_varying_cox <- function(train_data, test_data) {
  
  train_data <- train_data %>%
    mutate(interval_time = stop - start)
  test_data <- test_data %>%
    mutate(interval_time = stop - start)
  
  predictors <- setdiff(names(train_data), c("start", "stop", "event", "ID", "interval_time"))
  # Scale the predictors
  train_data <- train_data %>%
    mutate(across(everything(), as.numeric)) %>%
    mutate(across(all_of(predictors), ~ scale(.)[, 1]))
  test_data <- test_data %>%
    mutate(across(everything(), as.numeric)) %>%
    mutate(across(all_of(predictors), ~ scale(.)[, 1]))

  # train_data <- train_data %>%
  #   mutate(across(everything(), as.numeric)) %>%
  #   mutate(across(all_of(predictors), ~ (. - min(.)) / (max(.) - min(.))))
  # test_data <- test_data %>%
  #   mutate(across(everything(), as.numeric)) %>%
  #   mutate(across(all_of(predictors), ~ (. - min(.)) / (max(.) - min(.))))
  # 

  ###### Fit Cox proportional hazards model
  formula <- as.formula(paste("Surv(start, stop, event) ~", paste(predictors, collapse = " + ")))
  cox_model <- coxph(formula, data = train_data, id = train_data$ID, ties = "efron")
  ##########
  
  # interaction_terms <- paste0(c("APOE4", "edu"), ":interval_time")  # Interaction terms
  # all_predictors_with_interactions <- c(predictors, interaction_terms)
  # formula_interaction <- as.formula(paste(
  #   "Surv(start, stop, event) ~", 
  #   paste(all_predictors_with_interactions, collapse = " + ")
  # ))
  # cox_model <- coxph(formula_interaction, data = train_data, id = train_data$ID, ties = "efron")

  
  
  print(summary(cox_model))
  risk_scores_training <- predict(cox_model, newdata = train_data, type = "risk")
  risk_scores_testing <- predict(cox_model, newdata = test_data, type = "risk")
  
  
  risk_score_final_train <- data.frame(
    ID = train_data$ID,
    time = train_data$start,
    risk_score = risk_scores_training
  )
  final_risk_score_train <- risk_score_final_train %>%
    arrange(ID, time) %>% 
    group_by(ID) %>%
    filter(row_number() == n()) %>%
    summarise(last_risk_score = risk_score)
  
  risk_score_final_test <- data.frame(
    ID = test_data$ID,
    time = test_data$start,
    risk_score = risk_scores_testing
  )
  final_risk_score_test <- risk_score_final_test %>%
    arrange(ID, time) %>% 
    group_by(ID) %>%
    filter(row_number() == n()) %>%
    summarise(last_risk_score = risk_score)
  #########################

  # Compute C-index
  c_index <- concordance(cox_model, newdata = test_data)$concordance
  cat("C-index:", c_index, "\n")
  return(list(
    risk_train = final_risk_score_train,
    risk_test = final_risk_score_test,
    train_df= train_data
  ))
}

```

```{r}
analyze_risk_groups <- function(df, risk_group_df) {
  for (group in unique(risk_group_df$risk_group)) {
    cat(sprintf("\n--- Risk Group: %s ---\n", group))

    group_ids <- risk_group_df$ID[risk_group_df$risk_group == group]
    group_data <- df %>%
      filter(ID %in% group_ids) %>%
      arrange(ID, start)
    
    baseline <- group_data %>% group_by(ID) %>% slice(1) %>% ungroup()
    APOE4_positive_count <- sum(baseline$APOE4 == 1, na.rm = TRUE)
    APOE4_positive_percentage <- (APOE4_positive_count / nrow(baseline)) * 100
    gender_female_count <- sum(baseline$sex == 2, na.rm = TRUE)
    gender_female_percentage <- (gender_female_count / nrow(baseline)) * 100
    follow_up_intervals <- group_data %>% group_by(ID) %>%
      summarize(
        min_visit = min(start, na.rm = TRUE),
        max_visit = max(start, na.rm = TRUE)
      ) %>%
      ungroup()
    follow_up_range <- paste0(
      min(follow_up_intervals$max_visit, na.rm = TRUE),
      " - ",
      max(follow_up_intervals$max_visit, na.rm = TRUE),
      " months"
    )
    participants_with_event <- sum(group_data$event == 1, na.rm = TRUE)
    total_participants <- n_distinct(group_data$ID)
    AD_conversion_percentage <- (participants_with_event / total_participants) * 100
    if (participants_with_event > 0) {
      converters <- group_data %>% filter(event == 1)
      time_to_conversion <- converters %>%
        group_by(ID) %>%
        summarize(min_visit = min(start, na.rm = TRUE)) %>%
        ungroup() %>%
        pull(min_visit)
      time_to_conversion_mean <- mean(time_to_conversion, na.rm = TRUE)
      time_to_conversion_std <- sd(time_to_conversion, na.rm = TRUE)
    } else {
      time_to_conversion_mean <- NA
      time_to_conversion_std <- NA
    }

    # Print results
    total_participants <- length(unique(group_data$ID))
    cat(sprintf("Total participants: %d\n", total_participants))
    cat("APOE4 Positive (n, %):", APOE4_positive_count,
        "(", round(APOE4_positive_percentage, 2), "%)\n")
    cat("Gender (Female, n, %):", gender_female_count,
        "(", round(gender_female_percentage, 2), "%)\n")
    cat("Follow-up Interval:", follow_up_range, "\n")
    cat("AD Conversion (n, %):", participants_with_event,
        "(", round(AD_conversion_percentage, 2), "%)\n")
    if (!is.na(time_to_conversion_mean)) {
      cat("Time to AD Conversion (mean ± std):",
          round(time_to_conversion_mean, 2), "±",
          round(time_to_conversion_std, 2), "months\n")
    } else {
      cat("Time to AD Conversion (mean ± std): N/A\n")
    }
  }
}
```


```{r}
plot_centroid_trajectories <- function(df, risk_group, selected_features_trajectories, pdf_path) {
  common_time <- seq(min(df$start), max(df$start), length.out = 100)
  centroid_trajectories <- list()
  ci_trajectories <- list()

  for (feature in selected_features_trajectories) {
    centroid_trajectories[[feature]] <- lapply(unique(risk_group$risk_group), function(group) {
      group_ids <- risk_group$ID[risk_group$risk_group == group]
      group_data <- df %>%
        filter(ID %in% group_ids) %>%
        select(ID, start, all_of(feature))
      feature_matrix <- do.call(rbind, lapply(split(group_data, group_data$ID), function(df) {
        approx(x = df$start, y = df[[feature]], xout = common_time, rule = 2)$y
      }))
      
      list(mean = colMeans(feature_matrix, na.rm = TRUE),
           lower = apply(feature_matrix, 2, function(x) mean(x, na.rm = TRUE) - 1.96 * sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))),
           upper = apply(feature_matrix, 2, function(x) mean(x, na.rm = TRUE) + 1.96 * sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x))))
      )
    })
  }

  plot_list <- list()
  for (feature in selected_features_trajectories) {
    plot_data <- data.frame(
      Time = rep(common_time, times = length(unique(risk_group$risk_group))),
      Mean = unlist(lapply(centroid_trajectories[[feature]], `[[`, "mean")),
      Lower = unlist(lapply(centroid_trajectories[[feature]], `[[`, "lower")),
      Upper = unlist(lapply(centroid_trajectories[[feature]], `[[`, "upper")),
      Risk_Group = rep(unique(risk_group$risk_group), each = length(common_time))
    )
    p <- ggplot(plot_data, aes(x = Time, y = Mean, color = Risk_Group, fill = Risk_Group)) +
      geom_line(size = 1) +
      geom_ribbon(aes(ymin = Lower, ymax = Upper), alpha = 0.2, color = NA) +
      labs(
        title = feature,
        x = "Time",
        y = feature
      ) +
      theme_minimal() +
      theme(
        text = element_text(size = 10),
        plot.title = element_text(hjust = 0.5, size = 10),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()
      )

    plot_list[[feature]] <- p
  }

  # Save plots as a PDF
  pdf(pdf_path, width = 10, height = 8)
  grid.arrange(grobs = plot_list, ncol = 2, nrow = 2)
  dev.off()

  return(centroid_trajectories)
}


```



```{r}
NACC_full_df <- read.csv("../preprocessed_data/longitudinal_NACC_full.csv")
AIBL_full_df <- read.csv("../preprocessed_data/longitudinal_AIBL_full.csv")

selected_features = c("CDR_SB","memory_recall2", "animal", "APOE4", "edu", "MMSE")
index_feature = c("start", "stop", "event", "ID")
```

```{r}
AIBL_full_df_imputed<- missranger_impute(AIBL_full_df, c(c(index_feature), "Classification"))
```


```{r}
results <- external_validation_time_varying_cox(NACC_full_df[, unique(c(selected_features, index_feature))], AIBL_full_df_imputed[, unique(c(selected_features, index_feature))])
# results <- external_validation_time_varying_cox(AIBL_full_df_imputed[, unique(c(selected_features, index_feature))], NACC_full_df[, unique(c(selected_features, index_feature))])
# results <- external_validation_time_varying_cox(NACC_full_df[, unique(c(Cog_fts, demo_fts, basic_fts, index_feature))], AIBL_full_df_imputed[, unique(c(Cog_fts, demo_fts, basic_fts, index_feature))])
```


```{r}
risk_group_train <- results$risk_train %>%
  mutate(risk_group = case_when(
    last_risk_score < quantile(last_risk_score, 0.5) ~ "Low Risk",
    # last_risk_score < quantile(last_risk_score, 0.66) ~ "Medium Risk",
    TRUE ~ "High Risk"
  ))
analyze_risk_groups(NACC_full_df, risk_group_train)
```


```{r}
selected_features_trajectories = c("CDR_SB","memory_recall2", "animal", "MMSE")

centroid_trajectory_train = plot_centroid_trajectories(NACC_full_df, risk_group_train, selected_features_trajectories, "../results/feature_trajectories_NACC.pdf")
```



```{r}
risk_group_means_train <- sapply(unique(risk_group_train$risk_group), function(group) {
  group_ids <- risk_group_train$ID[risk_group_train$risk_group == group]
  subset_results <- results$risk_train[results$risk_train$ID %in% group_ids, ]
  mean(subset_results$last_risk_score, na.rm = TRUE)
})
names(risk_group_means_train) <- unique(risk_group_train$risk_group)
risk_group_means_train
```



External Validation, assign new participants

```{r}
risk_group_test <- results$risk_test %>%
  mutate(
    risk_group = sapply(last_risk_score, function(score) {
      differences <- abs(risk_group_means_train - score)
      names(differences)[which.min(differences)]
    })
  )

analyze_risk_groups(AIBL_full_df_imputed, risk_group_test)
```

```{r}
centroid_trajectory_test = plot_centroid_trajectories(AIBL_full_df_imputed, risk_group_test, selected_features_trajectories, "../results/feature_trajectories_AIBL.pdf")
```


```{r}
risk_group_means_test <- sapply(unique(risk_group_test$risk_group), function(group) {
  group_ids <- risk_group_test$ID[risk_group_test$risk_group == group]
  subset_results <- results$risk_test[results$risk_test$ID %in% group_ids, ]
  mean(subset_results$last_risk_score, na.rm = TRUE)
})
names(risk_group_means_test) <- unique(risk_group_test$risk_group)
risk_group_means_test
```

```{r}

```